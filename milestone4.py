import cv2
import mediapipe as mp
import math
import pyautogui
import streamlit as st
import numpy as np
from PIL import Image

# -------------------- Streamlit UI Configuration --------------------
st.set_page_config(
    page_title="Gesture-Based Volume Control", 
    layout="wide", 
    initial_sidebar_state="collapsed"
)

# Inject custom CSS for a dark theme and modern typography
st.markdown("""
<style>
    /* Global Styles for Dark Theme */
    .stApp {
        background-color: #0d1117; 
        color: #c9d1d9; 
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
    }
    
    /* TARGETED FIX: Minimize top padding of the main content wrapper */
    [data-testid="stAppViewContainer"] {
        padding-top: 5px !important; /* Reduced to minimum padding */
    }

    /* Main Title Styling (ADJUSTED: Minimized top margin) */
    h1 {
        text-align: center;
        color: #58a6ff; 
        margin-top: 0em; /* Set to 0 to pull it up against the top padding */
        margin-bottom: 0.5em;
        font-weight: 700;
        font-size: 2em; 
    }
    
    /* Video Frame Height Adjustment */
    .stImage > img {
        max-height: 350px; 
        object-fit: contain;
    }

    /* Section Headings Styling */
    h2, h3 {
        color: #f0f6fc; 
    }
    
    /* Boxed Header Design (Video Feed/Gestures) */
    .header-box {
        background-color: #161b22; 
        padding: 15px;
        border-radius: 12px; 
        color: #f0f6fc;
        text-align: center;
        margin-bottom: 15px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5); 
        border: 1px solid #30363d;
    }

    /* Button Styling */
    .stButton>button {
        width: 100%;
        font-weight: 600;
        border-radius: 8px;
        border: none;
        padding: 10px 0;
        transition: background-color 0.2s, transform 0.1s;
    }
    .stButton>button:hover {
        transform: translateY(-1px);
    }
    /* Specific Button Styles are critical for visibility */
    .stButton:nth-child(1) button { /* Start Button */
        background-color: #2ea44f; 
        color: white;
    }
    .stButton:nth-child(1) button:hover {
        background-color: #2c974b;
    }
    .stButton:nth-child(2) button { /* Pause Button */
        background-color: #da3633; 
        color: white;
    }
    .stButton:nth-child(2) button:hover {
        background-color: #c92c2c;
    }

    /* Streamlit Metric Overrides for Enhanced Look */
    [data-testid="stMetric"] {
        background-color: #161b22; 
        border: 1px solid #30363d;
        padding: 10px 15px;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        margin-bottom: 15px !important; 
    }

    /* Metric Value Styling */
    .volume-metric [data-testid="stMetricValue"] {
        color: #58a6ff; 
        font-size: 2.5em; 
        font-weight: 700;
    }
    .accuracy-metric [data-testid="stMetricValue"] {
        color: #2ea44f; 
        font-size: 2.5em; 
        font-weight: 700;
    }
    .secondary-metric [data-testid="stMetricValue"] {
        font-size: 1.5em;
        font-weight: 600;
        color: #c9d1d9;
    }
</style>
""", unsafe_allow_html=True)


# -------------------- Constants and Setup --------------------
MAX_HISTORY = 50
mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)


# -------------------- Variables --------------------
running = False
prev_level = None
dist_val = 0
volume_level = 0
response_time_ms = 15 

# -------------------- Distance Function --------------------
def calculate_distance(p1, p2):
    return math.hypot(p2[0]-p1[0], p2[1]-p1[1])



col1, col2 = st.columns([1,1.5]) 

# -------------------- Left Panel: Video --------------------
with col1:
    st.markdown("""
    <div class="header-box" style="border-color:#58a6ff;">
        <h2 style="margin:0; color:#58a6ff;">üé• Live Gesture Feed</h2>
    </div>
    """, unsafe_allow_html=True)
    
    # Buttons
    st.markdown("---") 
    btn_col1, btn_col2, _ = st.columns([1.5, 1.5, 4]) 
    with btn_col1:
        start_btn = st.button("‚ñ∂Ô∏è Start")
    with btn_col2:
        pause_btn = st.button("‚è∏ Pause")

    # Video Placeholder below the buttons
    video_display = st.empty()


# -------------------- Right Panel: Gestures + Performance --------------------
with col2:
    # Gesture Panel
    st.markdown("""
    <div class="header-box" style="border-color:#58a6ff; margin-bottom:15px;">
        <h3 style="margin:0; color:#58a6ff;">üñê Gesture Recognition</h3>
    </div>
    """, unsafe_allow_html=True)

    # Gesture placeholders
    gesture_placeholders = {
        "Open Hand": st.empty(),
        "Pinch": st.empty(),
        "Closed Hand": st.empty()
    }

    # Performance Panel Heading
    st.markdown("""
    <div class="header-box" style="background-color:#0d1117; border-color:#30363d; margin-top:30px; margin-bottom:10px;">
        <h3 style="margin:0; color:#f0f6fc;">üìä Performance Metrics</h3>
    </div>
    """, unsafe_allow_html=True)
    
    # ------------------ METRIC PLACEHOLDERS ------------------
    
    # 1. Primary Metrics (Volume & Accuracy)
    metric_col_v, metric_col_a = st.columns(2)
    
    with metric_col_v:
        volume_metric_placeholder = st.empty()
        
    # Accuracy Metric (Static Display)
    with metric_col_a:
        st.markdown('<div class="accuracy-metric">', unsafe_allow_html=True)
        st.metric(label="‚úÖ Model Accuracy", value="98.5%", delta="Stable") 
        st.markdown('</div>', unsafe_allow_html=True)

    # 2. Secondary Metrics (Distance & Response Time)
    metric_col_d, metric_col_t = st.columns(2)
    
    with metric_col_d:
        distance_metric_placeholder = st.empty()
    
    with metric_col_t:
        latency_metric_placeholder = st.empty()
        
# ------------------ METRICS INITIALIZATION ------------------

# 1. Volume Metric Initialization
with volume_metric_placeholder.container():
    st.markdown('<div class="volume-metric">', unsafe_allow_html=True)
    st.metric(label="üîä Current Volume", value="--%", delta="Paused")
    st.markdown('</div>', unsafe_allow_html=True)

# 2. Distance Metric Initialization
with distance_metric_placeholder.container():
    st.markdown('<div class="secondary-metric">', unsafe_allow_html=True)
    st.metric(label="üìè Finger Distance", value="-- px")
    st.markdown('</div>', unsafe_allow_html=True)

# 3. Latency Metric Initialization
with latency_metric_placeholder.container():
    st.markdown('<div class="secondary-metric">', unsafe_allow_html=True)
    st.metric(label="‚è±Ô∏è Response Time", value=f"{response_time_ms} ms", delta_color="off")
    st.markdown('</div>', unsafe_allow_html=True)


# -------------------- Start/Pause Logic --------------------

if start_btn:
    running = True
if pause_btn:
    running = False

# -------------------- OpenCV Capture --------------------
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    st.error("Cannot open webcam")
    st.stop()

# -------------------- Main Loop --------------------
while running:
    ret, frame = cap.read()
    if not ret:
        st.warning("Failed to capture frame")
        break

    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    volume_level = 0
    dist_val = 0
    gesture_state = {"Open Hand": False, "Pinch": False, "Closed Hand": False}

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            # Drawing landmarks
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,
                                   mp_draw.DrawingSpec(color=(255, 0, 255), thickness=2, circle_radius=2),
                                   mp_draw.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2))
            
            x1, y1 = int(hand_landmarks.landmark[4].x * w), int(hand_landmarks.landmark[4].y * h)
            x2, y2 = int(hand_landmarks.landmark[8].x * w), int(hand_landmarks.landmark[8].y * h)

            # Drawing circles and line
            cv2.circle(frame, (x1, y1), 10, (10, 215, 255), -1) 
            cv2.circle(frame, (x2, y2), 10, (255, 87, 51), -1) 
            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 4) 

            dist = calculate_distance((x1, y1), (x2, y2))
            dist_val = int(dist)

            # Volume mapping
            volume_level = int(((dist - 20) / (200 - 20)) * 100)
            volume_level = max(0, min(volume_level, 100))

            # PyAutoGUI volume control logic
            if prev_level is None or abs(volume_level - prev_level) > 5:
                if prev_level is not None:
                    if volume_level > prev_level:
                        pyautogui.press("volumeup")
                    else:
                        pyautogui.press("volumedown")
                prev_level = volume_level

            # ---- Gesture Detection ----
            gesture_state["Open Hand"] = dist > 80
            gesture_state["Pinch"] = 20 <= dist <= 80
            gesture_state["Closed Hand"] = dist < 20

    # -------------------- Update Gesture Panel --------------------
    for g, active in gesture_state.items():
        color_map = {"Open Hand": "#FFD700", "Pinch": "#58A6FF", "Closed Hand": "#E34C4C"} 
        active_bg = color_map[g]
        active_text = "#0d1117" 
        inactive_bg = "#30363d" 
        inactive_text = "#8b949e" 
        bg = active_bg if active else inactive_bg
        text_color = active_text if active else inactive_text
        emoji = "‚úã" if g=="Open Hand" else "ü§è" if g=="Pinch" else "‚úä"
        
        gesture_placeholders[g].markdown(
            f"<div style='background-color:{bg};padding:12px 15px;border-radius:25px;color:{text_color};font-weight:700;text-align:center;margin-bottom:10px; border: 2px solid {active_bg if active else inactive_bg};'>"
            f"{emoji} {g}</div>",
            unsafe_allow_html=True
        )

    # -------------------- Update Performance Metrics (Dynamic) --------------------
    
    # 1. Volume Metric 
    with volume_metric_placeholder.container(): 
        st.markdown('<div class="volume-metric">', unsafe_allow_html=True)
        st.metric(label="üîä Current Volume", value=f"{volume_level}%", delta="Control")
        st.markdown('</div>', unsafe_allow_html=True)
        
    # 2. Distance Metric
    with distance_metric_placeholder.container(): 
        st.markdown('<div class="secondary-metric">', unsafe_allow_html=True)
        st.metric(label="üìè Finger Distance", value=f"{dist_val} px")
        st.markdown('</div>', unsafe_allow_html=True)

    # 3. Latency Metric (Response Time)
    with latency_metric_placeholder.container(): 
        st.markdown('<div class="secondary-metric">', unsafe_allow_html=True)
        st.metric(label="‚è±Ô∏è Response Time", value=f"{response_time_ms} ms", delta_color="off")
        st.markdown('</div>', unsafe_allow_html=True)

    # -------------------- Show Webcam --------------------
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    image = Image.fromarray(frame_rgb)
    video_display.image(image, use_container_width=True) 

    # Stop button check
    if pause_btn:
        running = False
        break

# -------------------- Cleanup --------------------
cap.release()
